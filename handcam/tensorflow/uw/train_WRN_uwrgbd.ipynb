{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SlackerGPU: Using gpus [7] on server: ait-server-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/luke/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import SlackerGPU to set env variables, import tf (tf 1.4)\n",
    "from handcam.ltt.util import SlackerGPU\n",
    "slackerGPU = SlackerGPU.SlackerGPU(username='ltaverne',\n",
    "                                   desired_server='ait-server-03',\n",
    "                                   num_gpus=1)\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    del flags\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    del FLAGS\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "#State your dataset directory\n",
    "flags.DEFINE_string('dataset_dir', '/local/home/luke/datasets/rgbd-dataset/', 'String: Your dataset directory')\n",
    "flags.DEFINE_string('mode', 'train', 'train or eval.')\n",
    "flags.DEFINE_integer('image_size', 224, 'Image side length.')\n",
    "flags.DEFINE_integer('batch_size', 10, 'Batch size.')\n",
    "flags.DEFINE_integer('num_classes', 51, 'Number of classes.')\n",
    "flags.DEFINE_string('train_dir', '/tmp/luke/WRN/train',\n",
    "                           'Directory to keep training outputs.')\n",
    "flags.DEFINE_string('eval_dir', '/tmp/luke/WRN/eval',\n",
    "                           'Directory to keep eval outputs.')\n",
    "flags.DEFINE_integer('eval_batch_count', 10,\n",
    "                            'Number of batches to eval.')\n",
    "flags.DEFINE_bool('eval_once', False,\n",
    "                         'Whether evaluate the model only once.')\n",
    "flags.DEFINE_string('log_root', '/tmp/luke/WRN',\n",
    "                           'Directory to keep the checkpoints. Should be a '\n",
    "                           'parent directory of FLAGS.train_dir/eval_dir.')\n",
    "\n",
    "# The number of images in the validation set. You would have to know the total number of examples in advance. This is essentially your evaluation dataset.\n",
    "flags.DEFINE_float('validation_size', 0.1, 'Float: The proportion of examples in the dataset to be used for validation')\n",
    "\n",
    "# The number of shards per dataset split.\n",
    "flags.DEFINE_integer('num_shards', 1000, 'Int: Number of shards to split the TFRecord files')\n",
    "\n",
    "# Seed for repeatability.\n",
    "flags.DEFINE_integer('random_seed', 0, 'Int: Random seed to use for repeatability.')\n",
    "\n",
    "#Output filename for the naming the TFRecord file\n",
    "flags.DEFINE_string('tfrecord_filename', 'uw-rgbd', 'String: The output filename to name your TFRecord file')\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/luke/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Preprocessing.py, line 98)",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/local/home/luke/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2910\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-1-35bcafad8940>\"\u001b[0m, line \u001b[1;32m8\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    from handcam.ltt.datasets.handcam import HandCamDataHandler\n",
      "\u001b[0;36m  File \u001b[0;32m\"/local/home/luke/programming/master-thesis/python/ltt/datasets/handcam/HandCamDataHandler.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from handcam.ltt.util.Preprocessing import simple_crop_batch\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/local/home/luke/programming/master-thesis/python/ltt/util/Preprocessing.py\"\u001b[0;36m, line \u001b[0;32m98\u001b[0m\n\u001b[0;31m    x_rgb[i] = rotate(x_rgb[i], angle=angles[i], reshape=False)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import six\n",
    "import time\n",
    "from handcam.ltt.network.model.Wide_ResNet import wide_resnet_tf as resnet_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of int64s.\n",
    "    Args:\n",
    "    values: A scalar or list of values.\n",
    "    Returns:\n",
    "    a TF-Feature.\n",
    "    \"\"\"\n",
    "    if not isinstance(values, (tuple, list)):\n",
    "        values = [values]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "\n",
    "def bytes_feature(values):\n",
    "    \"\"\"Returns a TF-Feature of bytes.\n",
    "    Args:\n",
    "    values: A string.\n",
    "    Returns:\n",
    "    a TF-Feature.\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\n",
    "\n",
    "def _merge_rgb_depth(rgb, depth, label):\n",
    "    im = tf.concat([tf.cast(rgb,dtype=tf.float32), tf.cast(depth,dtype=tf.float32)], axis=2)\n",
    "    \n",
    "    # im = tf.transpose(im,[2,0,1])\n",
    "    im = tf.image.resize_image_with_crop_or_pad(im, 224, 224)\n",
    "    \n",
    "    return im, label\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    features = {\"image/rgb\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "                \"image/depth\": tf.FixedLenFeature((), tf.string, default_value=\"\"),\n",
    "              \"image/class/label\": tf.FixedLenFeature((), tf.int64, default_value=0)}\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    \n",
    "    rgb_img = tf.image.decode_image(parsed_features[\"image/rgb\"], channels=3)\n",
    "    # rgb_img.set_shape([None, 320, 640, 3])\n",
    "    \n",
    "    depth_img = tf.image.decode_image(parsed_features[\"image/depth\"], channels=1)\n",
    "    # depth_img.set_shape([None, 320, 640, 1])\n",
    "    \n",
    "    one_hot = tf.one_hot(parsed_features[\"image/class/label\"],len(class_names))\n",
    "    \n",
    "    # Flip\n",
    "    # rgb_img, depth_img, one_hot = _random_flip_lr(rgb_img, depth_img, one_hot)\n",
    "    \n",
    "    # Translate\n",
    "    # rgb_img, depth_img, one_hot = _random_translate(rgb_img, depth_img, one_hot)\n",
    "    \n",
    "    # Rotate\n",
    "    # rgb_img, depth_img, one_hot = _random_rotations(rgb_img, depth_img, one_hot)    \n",
    "    \n",
    "    # Merge\n",
    "    img, one_hot = _merge_rgb_depth(rgb_img, depth_img, one_hot)\n",
    "    \n",
    "    return img, one_hot\n",
    "\n",
    "def _random_rotations(rgb, depth, label):\n",
    "    rotate = np.random.rand()\n",
    "    \n",
    "    if rotate > 0.5:\n",
    "        angle = (-0.174 - 1.66)*np.random.rand() + 1.66 # Between -95 and 10 degrees\n",
    "        old_shape_rgb = rgb.shape\n",
    "        old_shape_depth = rgb.shape\n",
    "        # rgb.set_shape([480, 640, 3])\n",
    "        # depth.set_shape([480, 640, 1])\n",
    "        rgb = tf.contrib.image.rotate(rgb, angle)\n",
    "        depth = tf.contrib.image.rotate(depth, angle)\n",
    "\n",
    "        # rgb.set_shape(old_shape_rgb)\n",
    "        # depth.set_shape(old_shape_depth)\n",
    "\n",
    "        \n",
    "    return rgb, depth, label\n",
    "\n",
    "def _random_flip_lr(rgb, depth, label):\n",
    "    flip = np.random.rand()\n",
    "    \n",
    "    if flip > 0.5:\n",
    "        rgb = tf.image.flip_left_right(rgb)\n",
    "        depth = tf.image.flip_left_right(depth)\n",
    "        \n",
    "    return rgb, depth, label\n",
    "\n",
    "def _random_translate(rgb, depth, label):\n",
    "    translate = np.random.rand()\n",
    "    \n",
    "    # if translate > 0.5:\n",
    "    if True:\n",
    "        old_shape_rgb = rgb.shape\n",
    "        old_shape_depth = rgb.shape\n",
    "        rgb.set_shape([480, 640, 3])\n",
    "        depth.set_shape([480, 640, 1])\n",
    "        \n",
    "        transforms = [1, 0, 0, 0, 1, 0, 0, 0]\n",
    "        \n",
    "        transforms[2] = np.random.randint(-45,45) # x shift\n",
    "        transforms[5] = np.random.randint(-45,45) # y shift\n",
    "        \n",
    "        rgb = tf.contrib.image.transform(rgb, transforms)\n",
    "        depth = tf.contrib.image.transform(depth, transforms)\n",
    "        # \n",
    "        # rgb.set_shape(old_shape_rgb)\n",
    "        # depth.set_shape(old_shape_depth)\n",
    "        \n",
    "    return rgb, depth, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the dataset for uwrgbd\n",
    "dataset_root = FLAGS.dataset_dir\n",
    "class_names = sorted([i for i in next(os.walk(dataset_root))[1]])\n",
    "class_names_to_index = dict(zip(class_names,range(len(class_names))))\n",
    "\n",
    "test_tfrecord_path = FLAGS.dataset_dir + 'uw-rgbd_train_00000-of-00900.tfrecord'\n",
    "\n",
    "filenames_placeholder = tf.placeholder(tf.string, shape=[None])\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(filenames_placeholder)\n",
    "dataset = dataset.map(_parse_function, num_parallel_calls=4)\n",
    "\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(FLAGS.batch_size))\n",
    "# dataset = dataset.map(lambda x, y: (x.set_shape([16, 480,640, 4]), y))\n",
    "dataset = dataset.prefetch(1)\n",
    "\n",
    "# iterator = dataset.make_initializable_iterator()\n",
    "# iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)\n",
    "init_train = iterator.make_initializer(dataset)\n",
    "images, labels = iterator.get_next()\n",
    "\n",
    "train_tfrecord_filenames = [test_tfrecord_path]\n",
    "\n",
    "# sess = tf.Session('')\n",
    "# sess.run(iterator.initializer, feed_dict={filenames_placeholder: train_tfrecord_filenames})\n",
    "# \n",
    "# images, labels = iterator.get_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class _DatasetInitializerHook(tf.train.SessionRunHook):\n",
    "    def __init__(self, initializer, filenames_list):\n",
    "        self._initializer = initializer\n",
    "        self._filenames_list = filenames_list\n",
    "    def begin(self):\n",
    "        pass\n",
    "    def after_create_session(self, session, coord):\n",
    "        del coord\n",
    "        session.run(self._initializer, feed_dict={filenames_placeholder: self._filenames_list})\n",
    "            \n",
    "def train(hps):\n",
    "    \"\"\"Training loop.\"\"\"\n",
    "    # images, labels = sess.run(next_element)\n",
    "    # images_placeholder = tf.placeholder(tf.float32, shape=[FLAGS.batch_size, 480, 640, 4], name='images_placeholder')\n",
    "    # labels_placeholder = tf.placeholder(tf.float32, shape=[FLAGS.batch_size, FLAGS.num_classes], name='labels_placeholder')\n",
    "    model = resnet_model.ResNet(hps, images, labels, FLAGS.mode, batch_size=FLAGS.batch_size)\n",
    "    model.build_graph()\n",
    "    \n",
    "\n",
    "    param_stats = tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
    "        tf.get_default_graph(),\n",
    "        tfprof_options=tf.contrib.tfprof.model_analyzer.\n",
    "        TRAINABLE_VARS_PARAMS_STAT_OPTIONS)\n",
    "    sys.stdout.write('total_params: %d\\n' % param_stats.total_parameters)\n",
    "\n",
    "    tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
    "        tf.get_default_graph(),\n",
    "        tfprof_options=tf.contrib.tfprof.model_analyzer.FLOAT_OPS_OPTIONS)\n",
    "\n",
    "    truth = tf.argmax(model.labels, axis=1)\n",
    "    predictions = tf.argmax(model.predictions, axis=1)\n",
    "    precision = tf.reduce_mean(tf.to_float(tf.equal(predictions, truth)))\n",
    "\n",
    "    summary_hook = tf.train.SummarySaverHook(\n",
    "        save_steps=100,\n",
    "        output_dir=FLAGS.train_dir,\n",
    "        summary_op=tf.summary.merge([model.summaries,\n",
    "                                     tf.summary.scalar('Precision', precision)]))\n",
    "\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors={'step': model.global_step,\n",
    "                 'loss': model.cost,\n",
    "                 'precision': precision},\n",
    "        every_n_iter=100)\n",
    "\n",
    "    class _LearningRateSetterHook(tf.train.SessionRunHook):\n",
    "        \"\"\"Sets learning_rate based on global step.\"\"\"\n",
    "\n",
    "        def begin(self):\n",
    "            self._lrn_rate = 0.1\n",
    "\n",
    "        def before_run(self, run_context):\n",
    "            return tf.train.SessionRunArgs(\n",
    "                model.global_step,  # Asks for global step value.\n",
    "                feed_dict={model.lrn_rate: self._lrn_rate})  # Sets learning rate\n",
    "\n",
    "        def after_run(self, run_context, run_values):\n",
    "            train_step = run_values.results\n",
    "            if train_step < 40000:\n",
    "                self._lrn_rate = 0.1\n",
    "            elif train_step < 60000:\n",
    "                self._lrn_rate = 0.01\n",
    "            elif train_step < 80000:\n",
    "                self._lrn_rate = 0.001\n",
    "            else:\n",
    "                self._lrn_rate = 0.0001\n",
    "                \n",
    "    initializer_hook = _DatasetInitializerHook(init_train, train_tfrecord_filenames)\n",
    "\n",
    "    with tf.train.MonitoredTrainingSession(\n",
    "            checkpoint_dir=FLAGS.log_root,\n",
    "            hooks=[initializer_hook, logging_hook, _LearningRateSetterHook()],\n",
    "            chief_only_hooks=[summary_hook],\n",
    "            # Since we provide a SummarySaverHook, we need to disable default\n",
    "            # SummarySaverHook. To do that we set save_summaries_steps to 0.\n",
    "            save_summaries_steps=0,\n",
    "            config=tf.ConfigProto(allow_soft_placement=True)) as mon_sess:\n",
    "        while not mon_sess.should_stop():\n",
    "            mon_sess.run(model.train_op)\n",
    "            \n",
    "\n",
    "\n",
    "def evaluate(hps):\n",
    "    \"\"\"Eval loop.\"\"\"\n",
    "    model = resnet_model.ResNet(hps, images, labels, FLAGS.mode, batch_size=FLAGS.batch_size)\n",
    "    model.build_graph()\n",
    "    saver = tf.train.Saver()\n",
    "    summary_writer = tf.summary.FileWriter(FLAGS.eval_dir)\n",
    "\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    sess.run(init_train, feed_dict={filenames_placeholder: train_tfrecord_filenames})\n",
    "    # tf.train.start_queue_runners(sess)\n",
    "\n",
    "    best_precision = 0.0\n",
    "    while True:\n",
    "        try:\n",
    "            ckpt_state = tf.train.get_checkpoint_state(FLAGS.log_root)\n",
    "        except tf.errors.OutOfRangeError as e:\n",
    "            tf.logging.error('Cannot restore checkpoint: %s', e)\n",
    "            continue\n",
    "        if not (ckpt_state and ckpt_state.model_checkpoint_path):\n",
    "            tf.logging.info('No model to eval yet at %s', FLAGS.log_root)\n",
    "            continue\n",
    "        tf.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)\n",
    "        saver.restore(sess, ckpt_state.model_checkpoint_path)\n",
    "\n",
    "        total_prediction, correct_prediction = 0, 0\n",
    "        for _ in six.moves.range(FLAGS.eval_batch_count):\n",
    "            (summaries, loss, predictions, truth, train_step) = sess.run(\n",
    "                [model.summaries, model.cost, model.predictions,\n",
    "                 model.labels, model.global_step])\n",
    "\n",
    "            truth = np.argmax(truth, axis=1)\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "            correct_prediction += np.sum(truth == predictions)\n",
    "            total_prediction += predictions.shape[0]\n",
    "\n",
    "        precision = 1.0 * correct_prediction / total_prediction\n",
    "        best_precision = max(precision, best_precision)\n",
    "\n",
    "        precision_summ = tf.Summary()\n",
    "        precision_summ.value.add(\n",
    "            tag='Precision', simple_value=precision)\n",
    "        summary_writer.add_summary(precision_summ, train_step)\n",
    "        best_precision_summ = tf.Summary()\n",
    "        best_precision_summ.value.add(\n",
    "            tag='Best Precision', simple_value=best_precision)\n",
    "        summary_writer.add_summary(best_precision_summ, train_step)\n",
    "        summary_writer.add_summary(summaries, train_step)\n",
    "        tf.logging.info('loss: %.3f, precision: %.3f, best precision: %.3f' %\n",
    "                        (loss, precision, best_precision))\n",
    "        summary_writer.flush()\n",
    "\n",
    "        if FLAGS.eval_once:\n",
    "            break\n",
    "\n",
    "        time.sleep(60)\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    hps = resnet_model.HParams(batch_size=FLAGS.batch_size,\n",
    "                               num_classes=FLAGS.num_classes,\n",
    "                               min_lrn_rate=0.0001,\n",
    "                               lrn_rate=0.1,\n",
    "                               num_residual_units=5,\n",
    "                               use_bottleneck=False,\n",
    "                               weight_decay_rate=0.0002,\n",
    "                               relu_leakiness=0.1,\n",
    "                               optimizer='mom')\n",
    "\n",
    "    if FLAGS.mode == 'train':\n",
    "        train(hps)\n",
    "    elif FLAGS.mode == 'eval':\n",
    "        evaluate(hps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64)\n(10, 64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /local/home/luke/programming/master-thesis/python/ltt/network/model/Wide_ResNet/wide_resnet_tf.py:299: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-2ed5cb1cdaea>:22: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\nInstructions for updating:\nUse `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "627 ops no flops stats due to incomplete shapes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_params: 466963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "627 ops no flops stats due to incomplete shapes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/luke/WRN/model.ckpt-17273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 17274 into /tmp/luke/WRN/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 0.9, loss = 0.6949687, step = 17274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.48792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 0.8, loss = 0.9185536, step = 17374 (64.644 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.74518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.44158846, step = 17474 (57.301 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.76036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.30137616, step = 17574 (56.807 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.76519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.4499274, step = 17674 (56.651 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.69247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 0.9, loss = 0.40169448, step = 17774 (59.085 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.70908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 0.7, loss = 1.2600349, step = 17874 (58.511 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.80516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 0.8, loss = 0.93669486, step = 17974 (55.403 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.75922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.3276121, step = 18074 (56.837 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.90364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.31759042, step = 18174 (52.532 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.93486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 0.9, loss = 0.4417161, step = 18274 (51.683 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 18327 into /tmp/luke/WRN/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.8304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.3446307, step = 18374 (54.633 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.72312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.46213245, step = 18474 (58.034 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.78326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 0.8, loss = 1.244092, step = 18574 (56.080 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.82295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.34128976, step = 18674 (54.853 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.73847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.3725732, step = 18774 (57.533 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.86565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 0.9, loss = 0.47606423, step = 18874 (53.592 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.69509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.31068558, step = 18974 (58.994 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.72252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.2962522, step = 19074 (58.058 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.66327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.28942552, step = 19174 (60.117 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.7195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.2809822, step = 19274 (58.172 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 19369 into /tmp/luke/WRN/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.56067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.27202564, step = 19374 (64.061 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.61512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.2679613, step = 19474 (61.913 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.5696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.2479493, step = 19574 (63.710 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.70751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.23799819, step = 19674 (58.579 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.59271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.23191817, step = 19774 (62.778 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.75504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.22599341, step = 19874 (57.046 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.71802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.22122145, step = 19974 (58.138 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.75442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.21123724, step = 20074 (57.001 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.72814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.2003391, step = 20174 (57.860 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.88578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.19412859, step = 20274 (53.030 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.85444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.18454206, step = 20374 (53.929 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 20396 into /tmp/luke/WRN/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.76725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.1887223, step = 20474 (56.580 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.89614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.17594394, step = 20574 (52.738 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.79958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.1675944, step = 20674 (55.581 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.9679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.16577537, step = 20774 (50.804 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.79312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.15737464, step = 20874 (55.769 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.65954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.15928094, step = 20974 (60.258 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.71439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.14977856, step = 21074 (58.334 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.75289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.14329073, step = 21174 (57.061 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.58902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.13972126, step = 21274 (62.916 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.65531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.13340725, step = 21374 (60.414 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 21441 into /tmp/luke/WRN/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.53667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.1269993, step = 21474 (65.075 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.59915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.12273563, step = 21574 (62.532 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.60414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.1199385, step = 21674 (62.376 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.70765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:precision = 1.0, loss = 0.1255741, step = 21774 (58.523 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2f3e3eb251b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2ed5cb1cdaea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2ed5cb1cdaea>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(hps)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# model.labels = labels2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    893\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/mkl_dnn/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
